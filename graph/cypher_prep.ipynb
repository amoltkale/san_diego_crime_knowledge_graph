{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c19bca67-2d97-4e3b-9a10-aa66df3d56f5",
   "metadata": {},
   "source": [
    "# Police nodes\n",
    "\n",
    "\n",
    "# reddit nodes (NECESSARY, TBD)\n",
    "## posts\n",
    "* source: merged_df found below in reddit sections\n",
    "* node id: post id\n",
    "* attributes\n",
    "    * url\n",
    "    * post title\n",
    "    * keywords (may be empty)\n",
    "        * format with \";\" delimiter\n",
    "    * (future ideas: tot comments, upvotes, has media, etc) \n",
    "\n",
    "## users (NOT NECESSARY, TBD, NICE TO HAVE)\n",
    "* source: original cleaned reddit data\n",
    "* node id: author\n",
    "* attributes\n",
    "    * has_posted?\n",
    "    * has commented?\n",
    "\n",
    "# nextdoor nodes (NECESSARY, TBD)\n",
    "* source: nd_keywords_ner.csv\n",
    "* node_id: post_id\n",
    "* attributes\n",
    "    * ShortUrl\n",
    "    * keywords\n",
    "    * cannot have post title\n",
    "\n",
    "# police data nodes (NECESSARY, DONE)\n",
    "* node_id: incident_id\n",
    "* attributes\n",
    "    * priority\n",
    "    * crime_type (we manually populated)\n",
    "\n",
    "# Crime corpus nodes (NECESSARY, DONE)\n",
    "* node: crime type\n",
    "\n",
    "# Neighborhood corpus nodes (NECESSARY, DONE)\n",
    "* node: neighborhood location\n",
    "\n",
    "# Time nodes (DONE)\n",
    "\n",
    "# Relationships\n",
    "\n",
    "## Reddit (NOT NECESSARY, nice to have)\n",
    "* start_id = user id\n",
    "* end_id = post id\n",
    "* type: comment, post\n",
    "\n",
    "## Crime (BELONGS_TO) (NECESSARY)\n",
    "* start_id = crime post/call (reddit, nextdoor, police data)\n",
    "* end_id = crime node (crime corpus)\n",
    "* source type = reddit, nextdoor, police calls (:TYPE)\n",
    "* time type = time bin\n",
    "* neighborhood type?\n",
    "\n",
    "## Crime (HAPPENED_IN) (NECESSARY)\n",
    "* start_id = crime post/call\n",
    "* end_id = neighborhood node\n",
    "* source type = reddit, nextdoor, police calls (:TYPE)\n",
    "\n",
    "## Crime (HAPPENED_AT) (TBD, nice to have)\n",
    "* start_id = crime post/call\n",
    "* end_id = time\n",
    "* source type = reddit, nextdoor, police calls (:TYPE)\n",
    "\n",
    "## Other relationships\n",
    "ethinicity/drugs?/immigration?\n",
    "General pattern:\n",
    "start_id: reddit, nextdoor, police\n",
    "end_id: corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c205bdba-fa14-4250-8387-afa7fafde68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pathlib import Path\n",
    "import string\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../data_cleaning_and_integration')\n",
    "\n",
    "from cleaner_lib import remove_puncuations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38f95170-dc57-4487-a017-209051db9ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set paths\n",
    "data_p             = Path(\"../data\")\n",
    "\n",
    "corpi_p            = data_p / \"corpi\"\n",
    "neighborhood_p     = corpi_p / \"neighborhood_corpus_binned.csv\"\n",
    "crime_p            = corpi_p / \"crime_corpus_binned.csv\"\n",
    "\n",
    "reddit_processed_p = data_p / \"processed_reddit_data\"\n",
    "nd_processed_p = data_p / \"processed_nextdoor_data\"\n",
    "pd_processed_p = data_p / \"processed_pd_data\"\n",
    "\n",
    "# create out path\n",
    "out_p = data_p / \"neo4j_files\"\n",
    "out_p.mkdir(exist_ok=True)\n",
    "\n",
    "node_p = out_p / \"nodes\"\n",
    "node_p.mkdir(exist_ok=True)\n",
    "\n",
    "relations_p = out_p / \"relationships\"\n",
    "relations_p.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "neighborhood_out_p = node_p / \"neighborhood_nodes.csv\"\n",
    "crime_out_p = node_p / \"crime_nodes.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befe277a-095b-4829-be85-de53f1f29ce7",
   "metadata": {},
   "source": [
    "## Make Corpi Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63ee3c4f-4026-4c61-a6ba-422b2f41067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in neighborhood corpus and write to node file\n",
    "neighborhood_df = pd.read_csv(neighborhood_p)\n",
    "neighborhood_df.rename(columns = {'neighborhood_set_id':'neighborhood_set_id:ID',\n",
    "                                 'neighborhood_set':'neighborhood_set:string[]'},inplace=True)\n",
    "neighborhood_df[\":LABEL\"] = \"neighborhood\"\n",
    "node_neighborhood_df = neighborhood_df[[\"neighborhood_set_id:ID\", \"neighborhood_set:string[]\", \":LABEL\"]].copy()\n",
    "node_neighborhood_df.drop_duplicates(inplace=True)\n",
    "node_neighborhood_df.to_csv(neighborhood_out_p, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c99fbbda-1287-48c3-ba39-afeecfa919e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in neighborhood corpus and write to node file\n",
    "crime_df = pd.read_csv(crime_p)\n",
    "\n",
    "crime_df.rename(columns = {'crime_set_id':'crime_set_id:ID',\n",
    "                                 'crime_set':'crime_set:string[]'},inplace=True)\n",
    "crime_df[\":LABEL\"] = \"crime\"\n",
    "crime_df = crime_df[[\"crime_set_id:ID\", \"crime_set:string[]\", \":LABEL\"]]\n",
    "crime_df.drop_duplicates(inplace=True)\n",
    "crime_df.to_csv(crime_out_p, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063917a3-6f1c-4a83-af32-49d743bb5843",
   "metadata": {},
   "source": [
    "## Reditt Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441faecc-03ea-4e58-b15a-9d74574725b9",
   "metadata": {},
   "source": [
    "### Reddit: Merge NER and Rake results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422b42b1-21d3-4200-85a5-8816b53b9c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_p = reddit_processed_p / \"cleaned_reddit_ner_12-21_to_1115.csv\"\n",
    "keywords_p = reddit_processed_p / \"keyword_extraction.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8af040a-9267-4682-be1a-7c832b1deb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations: 43421\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_author</th>\n",
       "      <th>post_utc</th>\n",
       "      <th>full_link</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_text_count</th>\n",
       "      <th>ORG</th>\n",
       "      <th>DATE</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>FAC</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>LAW</th>\n",
       "      <th>LOC</th>\n",
       "      <th>NORP</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sandiego</td>\n",
       "      <td>going to visit san diego next week  any places...</td>\n",
       "      <td>x4nzh2</td>\n",
       "      <td>Fearmkultra</td>\n",
       "      <td>2022-09-03 06:57:58+00:00</td>\n",
       "      <td>https://www.reddit.com/r/sandiego/comments/x4n...</td>\n",
       "      <td>going to visit san diego next week any places ...</td>\n",
       "      <td>12</td>\n",
       "      <td>['san diego']</td>\n",
       "      <td>['next week']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sandiego</td>\n",
       "      <td>whaley house picture of ghost</td>\n",
       "      <td>x4ntm7</td>\n",
       "      <td>Open_Construction_31</td>\n",
       "      <td>2022-09-03 06:47:09+00:00</td>\n",
       "      <td>https://www.reddit.com/r/sandiego/comments/x4n...</td>\n",
       "      <td>whaley house picture of ghost as a kid i saw t...</td>\n",
       "      <td>199</td>\n",
       "      <td>['whaley house', 'the whaley house']</td>\n",
       "      <td>['13', '25 yrs ago']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['san diegans']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['a minute later', 'late nightearly morning']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sandiego</td>\n",
       "      <td>language exchange</td>\n",
       "      <td>x4n6xv</td>\n",
       "      <td>Poshorock</td>\n",
       "      <td>2022-09-03 06:07:46+00:00</td>\n",
       "      <td>https://www.reddit.com/r/sandiego/comments/x4n...</td>\n",
       "      <td>language exchange is there someone by there wh...</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['english']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['spanish']</td>\n",
       "      <td>['san diego']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SanDiegan</td>\n",
       "      <td>chula vista police stopping cars going east on...</td>\n",
       "      <td>x4n5aj</td>\n",
       "      <td>kaptaincorn</td>\n",
       "      <td>2022-09-03 06:04:54+00:00</td>\n",
       "      <td>https://www.reddit.com/r/SanDiegan/comments/x4...</td>\n",
       "      <td>chula vista police stopping cars going east on...</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['chula vista']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SanDiegan</td>\n",
       "      <td>todd gloria finalizes plan to change park blvd...</td>\n",
       "      <td>x4n2rv</td>\n",
       "      <td>Lemonade_IceCold</td>\n",
       "      <td>2022-09-03 06:00:38+00:00</td>\n",
       "      <td>https://www.reddit.com/r/SanDiegan/comments/x4...</td>\n",
       "      <td>todd gloria finalizes plan to change park blvd...</td>\n",
       "      <td>666</td>\n",
       "      <td>['gtonly']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['balboa park']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['north american']</td>\n",
       "      <td>['todd gloria', 'kevin']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                              title post_id  \\\n",
       "0   sandiego  going to visit san diego next week  any places...  x4nzh2   \n",
       "1   sandiego                      whaley house picture of ghost  x4ntm7   \n",
       "2   sandiego                                  language exchange  x4n6xv   \n",
       "3  SanDiegan  chula vista police stopping cars going east on...  x4n5aj   \n",
       "4  SanDiegan  todd gloria finalizes plan to change park blvd...  x4n2rv   \n",
       "\n",
       "            post_author                   post_utc  \\\n",
       "0           Fearmkultra  2022-09-03 06:57:58+00:00   \n",
       "1  Open_Construction_31  2022-09-03 06:47:09+00:00   \n",
       "2             Poshorock  2022-09-03 06:07:46+00:00   \n",
       "3           kaptaincorn  2022-09-03 06:04:54+00:00   \n",
       "4      Lemonade_IceCold  2022-09-03 06:00:38+00:00   \n",
       "\n",
       "                                           full_link  \\\n",
       "0  https://www.reddit.com/r/sandiego/comments/x4n...   \n",
       "1  https://www.reddit.com/r/sandiego/comments/x4n...   \n",
       "2  https://www.reddit.com/r/sandiego/comments/x4n...   \n",
       "3  https://www.reddit.com/r/SanDiegan/comments/x4...   \n",
       "4  https://www.reddit.com/r/SanDiegan/comments/x4...   \n",
       "\n",
       "                                           post_text  post_text_count  \\\n",
       "0  going to visit san diego next week any places ...               12   \n",
       "1  whaley house picture of ghost as a kid i saw t...              199   \n",
       "2  language exchange is there someone by there wh...               31   \n",
       "3  chula vista police stopping cars going east on...               57   \n",
       "4  todd gloria finalizes plan to change park blvd...              666   \n",
       "\n",
       "                                    ORG                  DATE EVENT  \\\n",
       "0                         ['san diego']         ['next week']   NaN   \n",
       "1  ['whaley house', 'the whaley house']  ['13', '25 yrs ago']   NaN   \n",
       "2                                   NaN                   NaN   NaN   \n",
       "3                                   NaN                   NaN   NaN   \n",
       "4                            ['gtonly']                   NaN   NaN   \n",
       "\n",
       "               FAC              GPE     LANGUAGE  LAW  LOC  \\\n",
       "0              NaN              NaN          NaN  NaN  NaN   \n",
       "1              NaN  ['san diegans']          NaN  NaN  NaN   \n",
       "2              NaN              NaN  ['english']  NaN  NaN   \n",
       "3              NaN  ['chula vista']          NaN  NaN  NaN   \n",
       "4  ['balboa park']              NaN          NaN  NaN  NaN   \n",
       "\n",
       "                 NORP                    PERSON  \\\n",
       "0                 NaN                       NaN   \n",
       "1                 NaN                       NaN   \n",
       "2         ['spanish']             ['san diego']   \n",
       "3                 NaN                       NaN   \n",
       "4  ['north american']  ['todd gloria', 'kevin']   \n",
       "\n",
       "                                            TIME  \n",
       "0                                            NaN  \n",
       "1  ['a minute later', 'late nightearly morning']  \n",
       "2                                            NaN  \n",
       "3                                            NaN  \n",
       "4                                            NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df = pd.read_csv(ner_p)\n",
    "print(f\"Total observations: {ner_df.shape[0]}\")\n",
    "\n",
    "# drop unamed index\n",
    "ner_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "ner_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acdfe1ce-40ef-4eeb-8b2a-7e327a31a408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subreddit', 'title', 'post_id', 'post_author', 'post_utc', 'full_link',\n",
       "       'post_text', 'post_text_count', 'ORG', 'DATE', 'EVENT', 'FAC', 'GPE',\n",
       "       'LANGUAGE', 'LAW', 'LOC', 'NORP', 'PERSON', 'TIME'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a15439-03c4-4021-bcd6-73e1b9cc74a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations: 31415\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x4ntm7</td>\n",
       "      <td>['suddenly appeared', 'something hard', 'smoke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x4n6xv</td>\n",
       "      <td>['language exchange', 'practice spanish', 'pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x4n5aj</td>\n",
       "      <td>['grand ave', 'seen', 'pb', 'holidays', 'end',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x4n2rv</td>\n",
       "      <td>['zoo uptown', 'working class', 'traffic elsew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x4mz7c</td>\n",
       "      <td>['verbal abuse', 'sell anything', 'extreme win...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                                           keywords\n",
       "0  x4ntm7  ['suddenly appeared', 'something hard', 'smoke...\n",
       "1  x4n6xv  ['language exchange', 'practice spanish', 'pra...\n",
       "2  x4n5aj  ['grand ave', 'seen', 'pb', 'holidays', 'end',...\n",
       "3  x4n2rv  ['zoo uptown', 'working class', 'traffic elsew...\n",
       "4  x4mz7c  ['verbal abuse', 'sell anything', 'extreme win..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_df = pd.read_csv(keywords_p)\n",
    "print(f\"Total observations: {keywords_df.shape[0]}\")\n",
    "keywords_df.drop(columns=['post_text'], inplace=True)\n",
    "keywords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72d759c6-cc4a-4ed8-ba81-cf3bd86bad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = ner_df.merge(keywords_df, left_on=\"post_id\", right_on=\"post_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022feb7d-2fce-41ca-bcb6-3c7312e8b13d",
   "metadata": {},
   "source": [
    "### Make Reddit nodes based on merged df across ner and keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8357243d-b9df-4436-b439-fb94aebfbfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_author</th>\n",
       "      <th>post_utc</th>\n",
       "      <th>full_link</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_text_count</th>\n",
       "      <th>ORG</th>\n",
       "      <th>DATE</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>FAC</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>LAW</th>\n",
       "      <th>LOC</th>\n",
       "      <th>NORP</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>TIME</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sandiego</td>\n",
       "      <td>going to visit san diego next week  any places...</td>\n",
       "      <td>x4nzh2</td>\n",
       "      <td>Fearmkultra</td>\n",
       "      <td>2022-09-03 06:57:58+00:00</td>\n",
       "      <td>https://www.reddit.com/r/sandiego/comments/x4n...</td>\n",
       "      <td>going to visit san diego next week any places ...</td>\n",
       "      <td>12</td>\n",
       "      <td>['san diego']</td>\n",
       "      <td>['next week']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sandiego</td>\n",
       "      <td>whaley house picture of ghost</td>\n",
       "      <td>x4ntm7</td>\n",
       "      <td>Open_Construction_31</td>\n",
       "      <td>2022-09-03 06:47:09+00:00</td>\n",
       "      <td>https://www.reddit.com/r/sandiego/comments/x4n...</td>\n",
       "      <td>whaley house picture of ghost as a kid i saw t...</td>\n",
       "      <td>199</td>\n",
       "      <td>['whaley house', 'the whaley house']</td>\n",
       "      <td>['13', '25 yrs ago']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['san diegans']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['a minute later', 'late nightearly morning']</td>\n",
       "      <td>['suddenly appeared', 'something hard', 'smoke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                              title post_id  \\\n",
       "0  sandiego  going to visit san diego next week  any places...  x4nzh2   \n",
       "1  sandiego                      whaley house picture of ghost  x4ntm7   \n",
       "\n",
       "            post_author                   post_utc  \\\n",
       "0           Fearmkultra  2022-09-03 06:57:58+00:00   \n",
       "1  Open_Construction_31  2022-09-03 06:47:09+00:00   \n",
       "\n",
       "                                           full_link  \\\n",
       "0  https://www.reddit.com/r/sandiego/comments/x4n...   \n",
       "1  https://www.reddit.com/r/sandiego/comments/x4n...   \n",
       "\n",
       "                                           post_text  post_text_count  \\\n",
       "0  going to visit san diego next week any places ...               12   \n",
       "1  whaley house picture of ghost as a kid i saw t...              199   \n",
       "\n",
       "                                    ORG                  DATE EVENT  FAC  \\\n",
       "0                         ['san diego']         ['next week']   NaN  NaN   \n",
       "1  ['whaley house', 'the whaley house']  ['13', '25 yrs ago']   NaN  NaN   \n",
       "\n",
       "               GPE LANGUAGE  LAW  LOC NORP PERSON  \\\n",
       "0              NaN      NaN  NaN  NaN  NaN    NaN   \n",
       "1  ['san diegans']      NaN  NaN  NaN  NaN    NaN   \n",
       "\n",
       "                                            TIME  \\\n",
       "0                                            NaN   \n",
       "1  ['a minute later', 'late nightearly morning']   \n",
       "\n",
       "                                            keywords  \n",
       "0                                                NaN  \n",
       "1  ['suddenly appeared', 'something hard', 'smoke...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a3c32-a699-44bb-be63-cde52b138d40",
   "metadata": {},
   "source": [
    "### Reddit Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85af5908-76c0-4857-bbbf-cf1e691ad530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of reddit_post_nodes_df (43273, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jg/d8_zwblj5ql38q843xmy7h9r0000gp/T/ipykernel_77152/502371629.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  reddit_post_nodes_df.keywords = reddit_post_nodes_df.keywords.str.replace('[', '')\n",
      "/var/folders/jg/d8_zwblj5ql38q843xmy7h9r0000gp/T/ipykernel_77152/502371629.py:8: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  reddit_post_nodes_df.keywords = reddit_post_nodes_df.keywords.str.replace(']', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id:ID</th>\n",
       "      <th>full_link</th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>:LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x4nzh2</td>\n",
       "      <td>https://www.reddit.com/r/sandiego/comments/x4n...</td>\n",
       "      <td>going to visit san diego next week  any places...</td>\n",
       "      <td></td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x4ntm7</td>\n",
       "      <td>https://www.reddit.com/r/sandiego/comments/x4n...</td>\n",
       "      <td>whaley house picture of ghost</td>\n",
       "      <td>'suddenly appeared'; 'something hard'; 'smoke ...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x4n6xv</td>\n",
       "      <td>https://www.reddit.com/r/sandiego/comments/x4n...</td>\n",
       "      <td>language exchange</td>\n",
       "      <td>'language exchange'; 'practice spanish'; 'prac...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x4n5aj</td>\n",
       "      <td>https://www.reddit.com/r/SanDiegan/comments/x4...</td>\n",
       "      <td>chula vista police stopping cars going east on...</td>\n",
       "      <td>'grand ave'; 'seen'; 'pb'; 'holidays'; 'end'; ...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x4n2rv</td>\n",
       "      <td>https://www.reddit.com/r/SanDiegan/comments/x4...</td>\n",
       "      <td>todd gloria finalizes plan to change park blvd...</td>\n",
       "      <td>'zoo uptown'; 'working class'; 'traffic elsewh...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43620</th>\n",
       "      <td>scdqum</td>\n",
       "      <td>https://www.reddit.com/r/UCSD/comments/scdqum/...</td>\n",
       "      <td>la jolla donor makes 50m research t that could...</td>\n",
       "      <td>'wasnt aware'; 'san diego'; 'never wondered'; ...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43621</th>\n",
       "      <td>sca7fv</td>\n",
       "      <td>https://www.reddit.com/r/UCSD/comments/sca7fv/...</td>\n",
       "      <td>new covid variant detected in at least 40 diff...</td>\n",
       "      <td>'sigma variant'; 'new shot'; 'like omicron'; '...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43622</th>\n",
       "      <td>sc9b5t</td>\n",
       "      <td>https://www.reddit.com/r/sandiego/comments/sc9...</td>\n",
       "      <td>tmz baltimore maggots leaked video twitter sca...</td>\n",
       "      <td></td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43623</th>\n",
       "      <td>sc90i4</td>\n",
       "      <td>https://www.reddit.com/r/UCSD/comments/sc90i4/...</td>\n",
       "      <td>mailing services while school’s online</td>\n",
       "      <td>'thing thankfully'; 'theyre forwarding'; 'pret...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43624</th>\n",
       "      <td>sc8vx6</td>\n",
       "      <td>https://www.reddit.com/r/sandiego/comments/sc8...</td>\n",
       "      <td>which san diego and metro area restaurant will...</td>\n",
       "      <td>'warning sign'; 'walk past'; 'us masters'; 'ta...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43273 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_id:ID                                          full_link  \\\n",
       "0         x4nzh2  https://www.reddit.com/r/sandiego/comments/x4n...   \n",
       "1         x4ntm7  https://www.reddit.com/r/sandiego/comments/x4n...   \n",
       "2         x4n6xv  https://www.reddit.com/r/sandiego/comments/x4n...   \n",
       "3         x4n5aj  https://www.reddit.com/r/SanDiegan/comments/x4...   \n",
       "4         x4n2rv  https://www.reddit.com/r/SanDiegan/comments/x4...   \n",
       "...          ...                                                ...   \n",
       "43620     scdqum  https://www.reddit.com/r/UCSD/comments/scdqum/...   \n",
       "43621     sca7fv  https://www.reddit.com/r/UCSD/comments/sca7fv/...   \n",
       "43622     sc9b5t  https://www.reddit.com/r/sandiego/comments/sc9...   \n",
       "43623     sc90i4  https://www.reddit.com/r/UCSD/comments/sc90i4/...   \n",
       "43624     sc8vx6  https://www.reddit.com/r/sandiego/comments/sc8...   \n",
       "\n",
       "                                                   title  \\\n",
       "0      going to visit san diego next week  any places...   \n",
       "1                          whaley house picture of ghost   \n",
       "2                                      language exchange   \n",
       "3      chula vista police stopping cars going east on...   \n",
       "4      todd gloria finalizes plan to change park blvd...   \n",
       "...                                                  ...   \n",
       "43620  la jolla donor makes 50m research t that could...   \n",
       "43621  new covid variant detected in at least 40 diff...   \n",
       "43622  tmz baltimore maggots leaked video twitter sca...   \n",
       "43623             mailing services while school’s online   \n",
       "43624  which san diego and metro area restaurant will...   \n",
       "\n",
       "                                                keywords :LABEL  \n",
       "0                                                          POST  \n",
       "1      'suddenly appeared'; 'something hard'; 'smoke ...   POST  \n",
       "2      'language exchange'; 'practice spanish'; 'prac...   POST  \n",
       "3      'grand ave'; 'seen'; 'pb'; 'holidays'; 'end'; ...   POST  \n",
       "4      'zoo uptown'; 'working class'; 'traffic elsewh...   POST  \n",
       "...                                                  ...    ...  \n",
       "43620  'wasnt aware'; 'san diego'; 'never wondered'; ...   POST  \n",
       "43621  'sigma variant'; 'new shot'; 'like omicron'; '...   POST  \n",
       "43622                                                      POST  \n",
       "43623  'thing thankfully'; 'theyre forwarding'; 'pret...   POST  \n",
       "43624  'warning sign'; 'walk past'; 'us masters'; 'ta...   POST  \n",
       "\n",
       "[43273 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reddit_post_node_file = node_p / 'reddit_post_nodes.csv'\n",
    "\n",
    "merged_df['post_id:ID'] = merged_df['post_id']\n",
    "reddit_post_nodes_df = merged_df[['post_id:ID','full_link','title','keywords']].copy()\n",
    "\n",
    "reddit_post_nodes_df.fillna(\"\", inplace=True)\n",
    "reddit_post_nodes_df.keywords = reddit_post_nodes_df.keywords.str.replace('[', '')\n",
    "reddit_post_nodes_df.keywords = reddit_post_nodes_df.keywords.str.replace(']', '')\n",
    "reddit_post_nodes_df.keywords = reddit_post_nodes_df.keywords.apply(lambda x: ';'.join(x.split(\",\")))\n",
    "reddit_post_nodes_df[':LABEL'] = 'POST'\n",
    "\n",
    "#Removing duplicate post ids.\n",
    "# Around 352 rows had duplicate post_id\n",
    "reddit_post_nodes_df = reddit_post_nodes_df[~reddit_post_nodes_df['post_id:ID'].duplicated()]\n",
    "print(\"shape of reddit_post_nodes_df\", reddit_post_nodes_df.shape)\n",
    "display(reddit_post_nodes_df)\n",
    "\n",
    "reddit_post_nodes_df.to_csv(reddit_post_node_file,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de3621d-6aad-4752-9964-312e11c5bbc2",
   "metadata": {},
   "source": [
    "Reddit happened_in relationship\n",
    "* crime related post happened_in neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecd8067-fb7c-42fd-9210-16cc45566a4d",
   "metadata": {},
   "source": [
    "### Nextdoor Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f64b6dd-5428-484f-a268-61915666ad10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>ShortLink</th>\n",
       "      <th>Author</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_text_count</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ORG</th>\n",
       "      <th>...</th>\n",
       "      <th>GPE</th>\n",
       "      <th>FAC</th>\n",
       "      <th>LOC</th>\n",
       "      <th>LAW</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>keywords</th>\n",
       "      <th>crime_score</th>\n",
       "      <th>ethnicity_score</th>\n",
       "      <th>neighborhood_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nd1</td>\n",
       "      <td>https://nextdoor.com/p/--3jc5nsXN58?view=detail</td>\n",
       "      <td>Hannah Lopez</td>\n",
       "      <td>how late can people be working on construction...</td>\n",
       "      <td>131</td>\n",
       "      <td>Corridor</td>\n",
       "      <td>tapebill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['willful violation', 'news trying', 'means ca...</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nd2</td>\n",
       "      <td>https://nextdoor.com/p/--mjpdwdS3yx?view=detail</td>\n",
       "      <td>Tim Welch</td>\n",
       "      <td>rain has finally arrived in north park but las...</td>\n",
       "      <td>280</td>\n",
       "      <td>Montclair</td>\n",
       "      <td>['chad jeremy 1964yeah', 'nicolas cage']</td>\n",
       "      <td>only 3 minutes</td>\n",
       "      <td>['tomorrow', 'yesterday', 'about two months la...</td>\n",
       "      <td>like.humidity</td>\n",
       "      <td>...</td>\n",
       "      <td>['china', 'san miguel de allende']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['“ yeah', 'vehicles chance', 'shall rebuild',...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nd3</td>\n",
       "      <td>https://nextdoor.com/p/-3GwdKj4_sMm?view=detail</td>\n",
       "      <td>News</td>\n",
       "      <td>dont we have a water shortage... jennifer that...</td>\n",
       "      <td>1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['jennifer', 'zanyface', 'agendawalter', 'wate...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['a day', '2 years ago', '5000 a month', '13',...</td>\n",
       "      <td>['sandags series', 'angelescarol dellangela']</td>\n",
       "      <td>...</td>\n",
       "      <td>['san francisco', 'san diego', 'differently.go...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['… enough', 'water usage', 'water situation',...</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nd4</td>\n",
       "      <td>https://nextdoor.com/p/-4qn3_2yNk_Y?view=detail</td>\n",
       "      <td>Frank Negrete</td>\n",
       "      <td>guess nd didnt like my question about drinking...</td>\n",
       "      <td>82</td>\n",
       "      <td>Hillcrest Northeast</td>\n",
       "      <td>['ndi’d', 'moderatorselectra hendrickson']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['public facewithtearsofjoy', 'faces bios', 'd...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nd5</td>\n",
       "      <td>https://nextdoor.com/p/-5-J-BXgJ84y?view=detail</td>\n",
       "      <td>Dawn Burton</td>\n",
       "      <td>day time robbery marston hillsupdate. update u...</td>\n",
       "      <td>1853</td>\n",
       "      <td>Hillcrest Southeast</td>\n",
       "      <td>['max', 'insanitylaurie hewitt', 'pam lauri', ...</td>\n",
       "      <td>['530 pm', 'morning', 'night', 'around midnigh...</td>\n",
       "      <td>['a month ago', 'age 2030', 'feb 26', 'about t...</td>\n",
       "      <td>['marston', 'nextdoor wvideo', 'dogood', 'your...</td>\n",
       "      <td>...</td>\n",
       "      <td>['california', 'california', 'essex st', 'verm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['yet nothing', 'violent felonies', 'unlawful ...</td>\n",
       "      <td>0.042534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                                        ShortLink         Author  \\\n",
       "0     nd1  https://nextdoor.com/p/--3jc5nsXN58?view=detail   Hannah Lopez   \n",
       "1     nd2  https://nextdoor.com/p/--mjpdwdS3yx?view=detail      Tim Welch   \n",
       "2     nd3  https://nextdoor.com/p/-3GwdKj4_sMm?view=detail           News   \n",
       "3     nd4  https://nextdoor.com/p/-4qn3_2yNk_Y?view=detail  Frank Negrete   \n",
       "4     nd5  https://nextdoor.com/p/-5-J-BXgJ84y?view=detail    Dawn Burton   \n",
       "\n",
       "                                           post_text  post_text_count  \\\n",
       "0  how late can people be working on construction...              131   \n",
       "1  rain has finally arrived in north park but las...              280   \n",
       "2  dont we have a water shortage... jennifer that...             1250   \n",
       "3  guess nd didnt like my question about drinking...               82   \n",
       "4  day time robbery marston hillsupdate. update u...             1853   \n",
       "\n",
       "          Neighborhood                                             PERSON  \\\n",
       "0             Corridor                                           tapebill   \n",
       "1            Montclair           ['chad jeremy 1964yeah', 'nicolas cage']   \n",
       "2                  NaN  ['jennifer', 'zanyface', 'agendawalter', 'wate...   \n",
       "3  Hillcrest Northeast         ['ndi’d', 'moderatorselectra hendrickson']   \n",
       "4  Hillcrest Southeast  ['max', 'insanitylaurie hewitt', 'pam lauri', ...   \n",
       "\n",
       "                                                TIME  \\\n",
       "0                                                NaN   \n",
       "1                                     only 3 minutes   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  ['530 pm', 'morning', 'night', 'around midnigh...   \n",
       "\n",
       "                                                DATE  \\\n",
       "0                                                NaN   \n",
       "1  ['tomorrow', 'yesterday', 'about two months la...   \n",
       "2  ['a day', '2 years ago', '5000 a month', '13',...   \n",
       "3                                                NaN   \n",
       "4  ['a month ago', 'age 2030', 'feb 26', 'about t...   \n",
       "\n",
       "                                                 ORG  ...  \\\n",
       "0                                                NaN  ...   \n",
       "1                                      like.humidity  ...   \n",
       "2      ['sandags series', 'angelescarol dellangela']  ...   \n",
       "3                                                NaN  ...   \n",
       "4  ['marston', 'nextdoor wvideo', 'dogood', 'your...  ...   \n",
       "\n",
       "                                                 GPE  FAC  LOC  LAW LANGUAGE  \\\n",
       "0                                                NaN  NaN  NaN  NaN      NaN   \n",
       "1                 ['china', 'san miguel de allende']  NaN  NaN  NaN      NaN   \n",
       "2  ['san francisco', 'san diego', 'differently.go...  NaN  NaN  NaN      NaN   \n",
       "3                                                NaN  NaN  NaN  NaN      NaN   \n",
       "4  ['california', 'california', 'essex st', 'verm...  NaN  NaN  NaN      NaN   \n",
       "\n",
       "  EVENT                                           keywords crime_score  \\\n",
       "0   NaN  ['willful violation', 'news trying', 'means ca...    0.005391   \n",
       "1   NaN  ['“ yeah', 'vehicles chance', 'shall rebuild',...    0.000000   \n",
       "2   NaN  ['… enough', 'water usage', 'water situation',...    0.008448   \n",
       "3   NaN  ['public facewithtearsofjoy', 'faces bios', 'd...    0.000000   \n",
       "4   NaN  ['yet nothing', 'violent felonies', 'unlawful ...    0.042534   \n",
       "\n",
       "   ethnicity_score  neighborhood_score  \n",
       "0              0.0            0.000000  \n",
       "1              0.0            0.002079  \n",
       "2              0.0            0.000000  \n",
       "3              0.0            0.000000  \n",
       "4              0.0            0.000000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source: ../data/processed_nextdoor_data/nd_keywords_ner.csv\n",
    "nd_merged_df = pd.read_csv(nd_processed_p / \"nd_keywords_ner.csv\")\n",
    "nd_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89b241dc-1b45-4c19-8e26-52c0646d82b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of nd_post_nodes_df (2808, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jg/d8_zwblj5ql38q843xmy7h9r0000gp/T/ipykernel_77152/2006162221.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  nd_post_nodes_df.keywords = nd_post_nodes_df.keywords.str.replace('[', '')\n",
      "/var/folders/jg/d8_zwblj5ql38q843xmy7h9r0000gp/T/ipykernel_77152/2006162221.py:8: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  nd_post_nodes_df.keywords = nd_post_nodes_df.keywords.str.replace(']', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id:ID</th>\n",
       "      <th>ShortLink</th>\n",
       "      <th>keywords</th>\n",
       "      <th>:LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nd1</td>\n",
       "      <td>https://nextdoor.com/p/--3jc5nsXN58?view=detail</td>\n",
       "      <td>'willful violation'; 'news trying'; 'means cap...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nd2</td>\n",
       "      <td>https://nextdoor.com/p/--mjpdwdS3yx?view=detail</td>\n",
       "      <td>'“ yeah'; 'vehicles chance'; 'shall rebuild'; ...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nd3</td>\n",
       "      <td>https://nextdoor.com/p/-3GwdKj4_sMm?view=detail</td>\n",
       "      <td>'… enough'; 'water usage'; 'water situation'; ...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nd4</td>\n",
       "      <td>https://nextdoor.com/p/-4qn3_2yNk_Y?view=detail</td>\n",
       "      <td>'public facewithtearsofjoy'; 'faces bios'; 'de...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nd5</td>\n",
       "      <td>https://nextdoor.com/p/-5-J-BXgJ84y?view=detail</td>\n",
       "      <td>'yet nothing'; 'violent felonies'; 'unlawful b...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>nd2817</td>\n",
       "      <td>https://nextdoor.com/p/zyBKcPsfG8p4?view=detail</td>\n",
       "      <td>'xxx amount'; 'vacation home'; 'uspspaula abso...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>nd2818</td>\n",
       "      <td>https://nextdoor.com/p/zzWdg8FDxMw4?view=detail</td>\n",
       "      <td>'sketchy scammy'; 'senders email'; 'scammichae...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>nd2819</td>\n",
       "      <td>https://nextdoor.com/p/zzYsgLb5T2sb?view=detail</td>\n",
       "      <td>'‘ charlie'; 'yrs old'; 'outcarol thank'; 'hi ...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>nd2820</td>\n",
       "      <td>https://nextdoor.com/p/zzgTmx49yTM4?view=detail</td>\n",
       "      <td>'tongueincheekdarn fireworks'; 'seconds apart'...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>nd2821</td>\n",
       "      <td>https://nextdoor.com/p/zznCjtcQpKsy?view=detail</td>\n",
       "      <td>'well people'; 'please let'; 'jeremy prayers';...</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2808 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id:ID                                        ShortLink  \\\n",
       "0           nd1  https://nextdoor.com/p/--3jc5nsXN58?view=detail   \n",
       "1           nd2  https://nextdoor.com/p/--mjpdwdS3yx?view=detail   \n",
       "2           nd3  https://nextdoor.com/p/-3GwdKj4_sMm?view=detail   \n",
       "3           nd4  https://nextdoor.com/p/-4qn3_2yNk_Y?view=detail   \n",
       "4           nd5  https://nextdoor.com/p/-5-J-BXgJ84y?view=detail   \n",
       "...         ...                                              ...   \n",
       "2803     nd2817  https://nextdoor.com/p/zyBKcPsfG8p4?view=detail   \n",
       "2804     nd2818  https://nextdoor.com/p/zzWdg8FDxMw4?view=detail   \n",
       "2805     nd2819  https://nextdoor.com/p/zzYsgLb5T2sb?view=detail   \n",
       "2806     nd2820  https://nextdoor.com/p/zzgTmx49yTM4?view=detail   \n",
       "2807     nd2821  https://nextdoor.com/p/zznCjtcQpKsy?view=detail   \n",
       "\n",
       "                                               keywords :LABEL  \n",
       "0     'willful violation'; 'news trying'; 'means cap...   POST  \n",
       "1     '“ yeah'; 'vehicles chance'; 'shall rebuild'; ...   POST  \n",
       "2     '… enough'; 'water usage'; 'water situation'; ...   POST  \n",
       "3     'public facewithtearsofjoy'; 'faces bios'; 'de...   POST  \n",
       "4     'yet nothing'; 'violent felonies'; 'unlawful b...   POST  \n",
       "...                                                 ...    ...  \n",
       "2803  'xxx amount'; 'vacation home'; 'uspspaula abso...   POST  \n",
       "2804  'sketchy scammy'; 'senders email'; 'scammichae...   POST  \n",
       "2805  '‘ charlie'; 'yrs old'; 'outcarol thank'; 'hi ...   POST  \n",
       "2806  'tongueincheekdarn fireworks'; 'seconds apart'...   POST  \n",
       "2807  'well people'; 'please let'; 'jeremy prayers';...   POST  \n",
       "\n",
       "[2808 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nd_post_node_file = node_p / 'nd_post_nodes.csv'\n",
    "\n",
    "nd_merged_df['post_id:ID'] = nd_merged_df['post_id']\n",
    "nd_post_nodes_df = nd_merged_df[['post_id:ID','ShortLink','keywords']].copy()\n",
    "\n",
    "nd_post_nodes_df.fillna(\"\", inplace=True)\n",
    "nd_post_nodes_df.keywords = nd_post_nodes_df.keywords.str.replace('[', '')\n",
    "nd_post_nodes_df.keywords = nd_post_nodes_df.keywords.str.replace(']', '')\n",
    "nd_post_nodes_df.keywords = nd_post_nodes_df.keywords.apply(lambda x: ';'.join(x.split(\",\")))\n",
    "nd_post_nodes_df[':LABEL'] = 'POST'\n",
    "\n",
    "print(\"shape of nd_post_nodes_df\", nd_post_nodes_df.shape)\n",
    "display(nd_post_nodes_df)\n",
    "\n",
    "nd_post_nodes_df.to_csv(nd_post_node_file,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff186c8-df05-44a0-8401-bdb89e6709d4",
   "metadata": {},
   "source": [
    "## Extracting Ethnicity for creating nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "785c6be1-680f-4f00-8196-a6c1fafa17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da8eb1e1-9653-4168-9386-afa09bc377f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dfindex</th>\n",
       "      <th>ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[english, spanish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>[american]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>[black]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>[white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>[black]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>43520</td>\n",
       "      <td>[white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>43561</td>\n",
       "      <td>[italy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>43581</td>\n",
       "      <td>[white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>43619</td>\n",
       "      <td>[german]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>43624</td>\n",
       "      <td>[asian]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2449 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dfindex           ethnicity\n",
       "0           2  [english, spanish]\n",
       "1           4          [american]\n",
       "2          47             [black]\n",
       "3          60             [white]\n",
       "4          88             [black]\n",
       "...       ...                 ...\n",
       "2444    43520             [white]\n",
       "2445    43561             [italy]\n",
       "2446    43581             [white]\n",
       "2447    43619            [german]\n",
       "2448    43624             [asian]\n",
       "\n",
       "[2449 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_corpus = pd.read_csv(corpi_p / 'ethnicity_corpus.csv')\n",
    "ethnicity_corpus.head()\n",
    "ethnicity_vectorizer = CountVectorizer(vocabulary = ethnicity_corpus['ethnicity'])\n",
    "ethnicity_vectorizer_matches = ethnicity_vectorizer.transform(merged_df['post_text'])\n",
    "ethnicity_exact_matches_df = pd.DataFrame({'dfindex': ethnicity_vectorizer_matches.nonzero()[0], \n",
    "                                      'ethnicityindex': ethnicity_vectorizer_matches.nonzero()[1]})\n",
    "ethnicity_exact_matches_df = ethnicity_exact_matches_df.merge(ethnicity_corpus, how = 'inner', \n",
    "                                                                    left_on = 'ethnicityindex', \n",
    "                                                                    right_index = True)\n",
    "ethnicity_exact_matches_df = ethnicity_exact_matches_df.groupby(by = 'dfindex', \n",
    "                                                                      as_index = False).agg({'ethnicity': lambda x: x.tolist()})\n",
    "ethnicity_exact_matches_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d5fda-b44c-446f-b325-d327485ab35f",
   "metadata": {},
   "source": [
    "### Police Calls data nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5095d0-0dd6-4ad6-a692-15ae2648c3ff",
   "metadata": {},
   "source": [
    "Police Crime nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9c90646-33ee-482d-8411-a3ce0e301e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Police Crime nodes\n",
    "\n",
    "pd_df = pd.read_csv(pd_processed_p / 'merged_pd_data.csv')\n",
    "\n",
    "##Change priority to int\n",
    "pd_df['priority'] = pd_df['priority'].astype(int)\n",
    "#droping duplicates\n",
    "pd_df.drop_duplicates(inplace=True)\n",
    "\n",
    "pd_df[\":LABEL\"] = \"REPORTED_CRIME\"\n",
    "\n",
    "pd_df['incident_num:ID'] = pd_df['incident_num']\n",
    "\n",
    "#re-arranging columns\n",
    "pd_crime_node_df = pd_df[['incident_num:ID','priority','crime_type',':LABEL']]\n",
    "\n",
    "pd_crime_node_df.to_csv(node_p / 'pd_crime_nodes.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2946b2b-f50e-4671-af5c-4bd435229c02",
   "metadata": {},
   "source": [
    "### (Police incident) -happened_in-> (neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d9545bd-6bd6-4c2f-bf6c-aa90b6c0a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neh_id_dict = dict(zip(neighborhood_df.neighborhood, neighborhood_df['neighborhood_set_id:ID']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0b19186-7087-4e4d-a81c-5d2183a7d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neh_id(neh):\n",
    "    '''This returns the neighborhood id from neighborhood'''\n",
    "    try:\n",
    "        return neh_id_dict[neh.lower()]\n",
    "    except:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63e2631a-7705-4dbd-bbd5-70c068d90014",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_happened_in_rel_df = pd_df.copy()\n",
    "\n",
    "# Looks like the initial corpus was create by replacing chars with space\n",
    "pd_happened_in_rel_df[\"neighborhood\"] = pd_happened_in_rel_df[\"neighborhood\"].replace('\\'', '', regex=True)\n",
    "pd_happened_in_rel_df[\"neighborhood\"] = pd_happened_in_rel_df[\"neighborhood\"].replace('/', ' ', regex=True)\n",
    "pd_happened_in_rel_df[\"neighborhood\"] = pd_happened_in_rel_df[\"neighborhood\"].replace('-', ' ', regex=True)\n",
    "\n",
    "pd_happened_in_rel_df = pd_happened_in_rel_df.rename(columns={'incident_num':'incident_num:START_ID'})\n",
    "non_na_neh = pd.notna(pd_happened_in_rel_df['neighborhood'])\n",
    "pd_happened_in_rel_df = pd_happened_in_rel_df[non_na_neh]\n",
    "pd_happened_in_rel_df = remove_puncuations(pd_happened_in_rel_df,'neighborhood')\n",
    "pd_happened_in_rel_df[':END_ID'] = pd_happened_in_rel_df['neighborhood'].apply(lambda x: get_neh_id(x))\n",
    "pd_happened_in_rel_df[':TYPE'] = 'HAPPENED_IN'\n",
    "pd_happened_in_rel_df = pd_happened_in_rel_df[pd_happened_in_rel_df[':END_ID']!='unknown']\n",
    "pd_happened_in_rel_df = pd_happened_in_rel_df[['incident_num:START_ID',':END_ID',':TYPE']]\n",
    "pd_happened_in_rel_df.to_csv(relations_p / 'police_HI_rels.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9277b08-cf4e-4dfc-8a8f-7e98c854c08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_num</th>\n",
       "      <th>date_time</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>address_number_primary</th>\n",
       "      <th>address_dir_primary</th>\n",
       "      <th>address_road_primary</th>\n",
       "      <th>address_sfx_primary</th>\n",
       "      <th>address_dir_intersecting</th>\n",
       "      <th>address_road_intersecting</th>\n",
       "      <th>address_sfx_intersecting</th>\n",
       "      <th>...</th>\n",
       "      <th>disposition</th>\n",
       "      <th>beat</th>\n",
       "      <th>priority</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>call_type_desc</th>\n",
       "      <th>crime_type</th>\n",
       "      <th>crime_focus</th>\n",
       "      <th>date_time_bin</th>\n",
       "      <th>:LABEL</th>\n",
       "      <th>incident_num:ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E22010000006</td>\n",
       "      <td>2022-01-01 00:01:14</td>\n",
       "      <td>7</td>\n",
       "      <td>4600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZION</td>\n",
       "      <td>AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>K</td>\n",
       "      <td>321</td>\n",
       "      <td>2</td>\n",
       "      <td>Grantville</td>\n",
       "      <td>DISTURBING PEACE</td>\n",
       "      <td>minor</td>\n",
       "      <td>person</td>\n",
       "      <td>Late Night</td>\n",
       "      <td>REPORTED_CRIME</td>\n",
       "      <td>E22010000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   incident_num            date_time  day_of_week  address_number_primary  \\\n",
       "0  E22010000006  2022-01-01 00:01:14            7                    4600   \n",
       "\n",
       "  address_dir_primary address_road_primary address_sfx_primary  \\\n",
       "0                 NaN                 ZION                 AVE   \n",
       "\n",
       "   address_dir_intersecting address_road_intersecting  \\\n",
       "0                       NaN                       NaN   \n",
       "\n",
       "   address_sfx_intersecting  ... disposition beat  priority  neighborhood  \\\n",
       "0                       NaN  ...           K  321         2    Grantville   \n",
       "\n",
       "     call_type_desc crime_type crime_focus date_time_bin          :LABEL  \\\n",
       "0  DISTURBING PEACE      minor      person    Late Night  REPORTED_CRIME   \n",
       "\n",
       "  incident_num:ID  \n",
       "0    E22010000006  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df[pd_df['incident_num:ID']=='E22010000006']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf03906a-46e6-4939-b4d6-054a05c79c1e",
   "metadata": {},
   "source": [
    "### REDDIT POST -HAPPENED_IN-> NEIGHBORHOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6f3f54f-df7e-4340-a159-3ea47f5747d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_serialized_list_chars(x):\n",
    "    return re.sub(\"\\[|\\]|'\", \"\", x).split(\",\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fc7f1f9-927b-4790-992f-c9559719ce40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reddit neighborhood\n",
    "reddit_crime_neighborhood_df = pd.read_csv(reddit_processed_p / 'reddit_crime_neighborhood.csv')\n",
    "\n",
    "#ignoring all the recs having empty list\n",
    "reddit_crime_neighborhood_df = reddit_crime_neighborhood_df[reddit_crime_neighborhood_df['neighborhood']!='[]']\n",
    "\n",
    "#Since on disk the lists were saved in string representation, need to de-serialize it again\n",
    "reddit_crime_neighborhood_df['neighborhood'] = reddit_crime_neighborhood_df['neighborhood'].apply(lambda x: remove_serialized_list_chars(x))\n",
    "reddit_crime_neighborhood_df = reddit_crime_neighborhood_df.explode(column='neighborhood')\n",
    "\n",
    "#rename column\n",
    "reddit_crime_neighborhood_df['post_id:START_ID'] = reddit_crime_neighborhood_df['post_id']\n",
    "\n",
    "#looking up the corpus file to get the correct END ID\n",
    "reddit_crime_neighborhood_df[':END_ID'] = reddit_crime_neighborhood_df['neighborhood'].apply(lambda x: get_neh_id(x.strip()))\n",
    "reddit_crime_neighborhood_df[':TYPE'] = 'HAPPENED_IN'\n",
    "\n",
    "#Join to make sure I pick only pos _id from the nodes\n",
    "reddit_crime_neighborhood_df = pd.merge(reddit_post_nodes_df, reddit_crime_neighborhood_df, left_on='post_id:ID', right_on='post_id:START_ID')\n",
    "\n",
    "\n",
    "reddit_crime_neighborhood_df = reddit_crime_neighborhood_df[['post_id:START_ID',':END_ID',':TYPE']]\n",
    "reddit_crime_neighborhood_df.to_csv(relations_p / 'reddit_HI_rels.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f2be7-f8bf-4de3-a634-c386129fc506",
   "metadata": {},
   "source": [
    "### NEXTDOOR POST -HAPPENED_IN-> NEIGHBORHOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ed025c2-7dc3-4e3c-9286-acfff2f315b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nextdoor neighborhood\n",
    "nd_crime_neighborhood_df = pd.read_csv( nd_processed_p / 'transitionary_files/nd_neighborhoods_matches.csv')\n",
    "nd_crime_neighborhood_df = nd_crime_neighborhood_df[nd_crime_neighborhood_df['neighborhood']!='[]']\n",
    "nd_crime_neighborhood_df['neighborhood'] = nd_crime_neighborhood_df['neighborhood'].apply(lambda x: remove_serialized_list_chars(x))\n",
    "nd_crime_neighborhood_df = nd_crime_neighborhood_df.explode(column='neighborhood')\n",
    "#rename column\n",
    "nd_crime_neighborhood_df['post_id:START_ID'] = nd_crime_neighborhood_df['post_id']\n",
    "nd_crime_neighborhood_df[':END_ID'] = nd_crime_neighborhood_df['neighborhood'].apply(lambda x: get_neh_id(x.strip()))\n",
    "nd_crime_neighborhood_df[':TYPE'] = 'HAPPENED_IN'\n",
    "\n",
    "#Join to make sure I pick only pos _id from the nodes\n",
    "nd_crime_neighborhood_df = pd.merge(nd_post_nodes_df, nd_crime_neighborhood_df, left_on='post_id:ID', right_on='post_id:START_ID')\n",
    "\n",
    "nd_crime_neighborhood_df = nd_crime_neighborhood_df[['post_id:START_ID',':END_ID',':TYPE']]\n",
    "nd_crime_neighborhood_df.to_csv(relations_p / 'nextdoor_HI_rels.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8e0cb-2505-4178-84a1-5607eea806fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
